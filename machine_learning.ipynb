{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2081cce3",
   "metadata": {},
   "source": [
    "# Discover the Higgs with Deep Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537f8d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e312205",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9615674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from numpy.random import seed\n",
    "import common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3357ffaf",
   "metadata": {},
   "source": [
    "The goal of this lab course is to train a deep neural network to separate Higgs boson signal from background events. The most important signal sample ggH125_ZZ4lep corresponds to the process gg->H->ZZ. The dominant background sample is llll resulting from Z and ZZ decays.\n",
    "After training the DNN model will be used to classify the events of the data samples.\n",
    "\n",
    "Higgs signal samples:\n",
    "- ggH125_ZZ4lep\n",
    "- VBFH125_ZZ4lep\n",
    "- WH125_ZZ4lep\n",
    "- ZH125_ZZ4lep\n",
    "\n",
    "Background samples:\n",
    "- llll\n",
    "- Zee\n",
    "- Zmumu\n",
    "- ttbar_lep\n",
    "\n",
    "Data samples:\n",
    "- data_A\n",
    "- data_B\n",
    "- data_C\n",
    "- data_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22a2ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input samples\n",
    "sample_list_signal = ['ggH125_ZZ4lep']\n",
    "sample_list_background = ['llll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e1b2ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the samples\n",
    "data_frames = {}\n",
    "for sample in sample_list_signal + sample_list_background:\n",
    "    data_frames[sample] = pd.read_csv('input/' + sample + \".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd6d51",
   "metadata": {},
   "source": [
    "Although the final selection of the data is to be performed on the basis of a DNN, a rough pre-selection of the data is still useful.\n",
    "Suitable criteria for this are basic selections that must be clearly fulfilled by H->ZZ->llll processes.\n",
    "\n",
    "Hint: What lepton types and charges are expected in the final state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ffa57853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_lep_type(lep_type_0, lep_type_1, lep_type_2, lep_type_3):\n",
    "    # Only keep events like eeee, mumumumu or eemumu\n",
    "    sum_lep_type = lep_type_0 + lep_type_1 + lep_type_2 + lep_type_3\n",
    "    return sum_lep_type == 44 or sum_lep_type == 48 or sum_lep_type == 52\n",
    "\n",
    "\n",
    "def cut_lep_charge(lep_charge_0, lep_charge_1, lep_charge_2, lep_charge_3):\n",
    "    # Only keep events where the sum of all lepton charges is zero\n",
    "    sum_lep_charge = lep_charge_0 + lep_charge_1 + lep_charge_2 + lep_charge_3\n",
    "    return sum_lep_charge == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13fc29db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the \n",
    "for sample in sample_list_signal + sample_list_background:\n",
    "    # Cut on lepton type\n",
    "    data_frames[sample] = data_frames[sample][np.vectorize(cut_lep_type)(\n",
    "        data_frames[sample].lep1_pdgId,\n",
    "        data_frames[sample].lep2_pdgId,\n",
    "        data_frames[sample].lep3_pdgId,\n",
    "        data_frames[sample].lep4_pdgId)]\n",
    "\n",
    "    # Cut on lepton charge\n",
    "    data_frames[sample] = data_frames[sample][np.vectorize(cut_lep_charge)(\n",
    "        data_frames[sample].lep1_charge,\n",
    "        data_frames[sample].lep2_charge,\n",
    "        data_frames[sample].lep3_charge,\n",
    "        data_frames[sample].lep4_charge)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "591b7e64",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'contact'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             output_data_frame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mcontact(output_data_frame, data_frames_dic[sample])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output_data_frame\n\u001b[0;32m---> 10\u001b[0m data_frame_signal \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_data_frames\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_list_signal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_frames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m data_frame_background \u001b[38;5;241m=\u001b[39m merge_data_frames(sample_list_background, data_frames)\n",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36mmerge_data_frames\u001b[0;34m(sample_list, data_frames_dic)\u001b[0m\n\u001b[1;32m      5\u001b[0m         output_data_frame \u001b[38;5;241m=\u001b[39m data_frames_dic[sample]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m         output_data_frame \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontact\u001b[49m(output_data_frame, data_frames_dic[sample])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_data_frame\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/__init__.py:244\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseArray \u001b[38;5;28;01mas\u001b[39;00m _SparseArray\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _SparseArray\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'contact'"
     ]
    }
   ],
   "source": [
    "# Merge the signal and background data frames\n",
    "def merge_data_frames(sample_list, data_frames_dic):\n",
    "    for sample in sample_list:\n",
    "        if sample == sample_list[0]:\n",
    "            output_data_frame = data_frames_dic[sample]\n",
    "        else:\n",
    "            output_data_frame = pd.contact(output_data_frame, data_frames_dic[sample])\n",
    "    return output_data_frame\n",
    "\n",
    "data_frame_signal = merge_data_frames(sample_list_signal, data_frames)\n",
    "data_frame_background = merge_data_frames(sample_list_background, data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = []\n",
    "variables.append({'variable': 'lep1_phi', 'bins': np.linspace(-3.4, 3.4, 100), 'xlabel': '$lep_{phi}$[1] [GeV]'})\n",
    "variables.append({'variable': 'lep1_eta', 'bins': np.linspace(-3.4, 3.4, 100), 'xlabel': '$lep_{eta}$[1] [GeV]'})\n",
    "variables.append({'variable': 'lep1_pt', 'bins': np.linspace(0, 200, 100), 'xlabel': '$lep_{pt}$[1] [GeV]'})\n",
    "variables.append({'variable': 'lep2_pt', 'bins': np.linspace(0, 150, 75), 'xlabel': '$lep_{pt}$[2] [GeV]'})\n",
    "variables.append({'variable': 'lep3_pt', 'bins': np.linspace(0, 150, 75), 'xlabel': '$lep_{pt}$[3] [GeV]'})\n",
    "variables.append({'variable': 'lep4_pt', 'bins': np.linspace(0, 100, 50), 'xlabel': '$lep_{pt}$[4] [GeV]'})\n",
    "variables.append({'variable': 'lep_m_llll', 'bins': np.linspace(0, 400, 100), 'xlabel': '$m_{llll}$ [GeV]'})\n",
    "variables.append({'variable': 'lep_m_ll_12', 'bins': np.linspace(0, 200, 100), 'xlabel': '$m_{ll}$[1,2] [GeV]'})\n",
    "variables.append({'variable': 'lep_m_ll_13', 'bins': np.linspace(0, 200, 100), 'xlabel': '$m_{ll}$[1,3] [GeV]'})\n",
    "variables.append({'variable': 'lep_m_ll_14', 'bins': np.linspace(0, 200, 100), 'xlabel': '$m_{ll}$[1,4] [GeV]'})\n",
    "variables.append({'variable': 'lep_m_ll_23', 'bins': np.linspace(0, 200, 100), 'xlabel': '$m_{ll}$[2,3] [GeV]'})\n",
    "variables.append({'variable': 'lep_m_ll_24', 'bins': np.linspace(0, 200, 100), 'xlabel': '$m_{ll}$[2,4] [GeV]'})\n",
    "variables.append({'variable': 'lep_m_ll_34', 'bins': np.linspace(0, 200, 100), 'xlabel': '$m_{ll}$[3,4] [GeV]'})\n",
    "for var in variables:\n",
    "    common.plot_hist(var, data_frame_signal, data_frame_background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7415e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggH125_ZZ4lep 24.769128960170892 161451\n",
      "data_A 0.0 27\n",
      "data_B 0.0 86\n",
      "data_C 0.0 146\n",
      "data_D 0.0 248\n",
      "llll 0.3029653353227194 523957\n"
     ]
    }
   ],
   "source": [
    "# This is not correct!!!!!\n",
    "for sample in sample_list_signal + sample_list_background:\n",
    "    print(sample, np.mean(data_frames[sample].weight), len(data_frames[sample].weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac0e9914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training input variables\n",
    "input_variable_list = ['lep1_pt', 'lep2_pt', 'lep3_pt', 'lep4_pt']\n",
    "#input_variable_list = ['lep_m_ll_12', 'lep_m_ll_13', 'lep_m_ll_14', 'lep_m_ll_23', 'lep_m_ll_24', 'lep_m_ll_34']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5a528eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training input\n",
    "input_values = []\n",
    "input_classification = []\n",
    "for sample in sample_list_signal + sample_list_background:\n",
    "    # Classify signal and background (and skip if data)\n",
    "    if sample in sample_list_signal:\n",
    "        # 1 if signal\n",
    "        input_classification.append(np.ones(len(data_frames[sample])))\n",
    "    elif sample in sample_list_background:\n",
    "        # 0 if background\n",
    "        input_classification.append(np.zeros(len(data_frames[sample])))\n",
    "    else:\n",
    "        continue\n",
    "    input_values.append(data_frames[sample][input_variable_list])\n",
    "\n",
    "# Merge the input\n",
    "input_values = np.concatenate(input_values)\n",
    "input_classification = np.concatenate(input_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "549adf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed=420)\n",
    "\n",
    "def split_indices(df, train_frac, test_frac, val_frac):\n",
    "    #assert train_frac + val_frac + test_frac <= 1\n",
    "    random_values = np.random.rand(len(df))\n",
    "    range1 = random_values <= train_frac\n",
    "    range2 = random_values <= train_frac + test_frac\n",
    "    range3 = random_values <= train_frac + test_frac + val_frac\n",
    "    train_index = range1\n",
    "    test_index = ~range1 & range2\n",
    "    val_index = ~range2 & range3\n",
    "    return train_index, test_index, val_index\n",
    "\n",
    "train_index, test_index, val_index = split_indices(input_values, 0.8, 0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e4c6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_values = input_values[train_index]\n",
    "train_input_classification = input_classification[train_index]\n",
    "test_input_values = input_values[test_index]\n",
    "test_input_classification = input_classification[test_index]\n",
    "val_input_values = input_values[val_index]\n",
    "val_input_classification = input_classification[val_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38a5368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "241de309",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  #tf.keras.layers.Flatten(input_shape=[len(input_variable_list)]),\n",
    "  tf.keras.layers.Dense(50, activation='relu'),\n",
    "  tf.keras.layers.Dense(50, activation='relu'),\n",
    "  #tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "682ad8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(train_input_values).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "077a6f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fe2b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1747d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_fn(train_input_classification, predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ef560b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7bcb36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "17153/17153 [==============================] - 56s 3ms/step - loss: 0.4033 - accuracy: 0.7892\n",
      "Epoch 2/5\n",
      "17153/17153 [==============================] - 56s 3ms/step - loss: 0.3544 - accuracy: 0.8333\n",
      "Epoch 3/5\n",
      "17153/17153 [==============================] - 51s 3ms/step - loss: 0.3491 - accuracy: 0.8355\n",
      "Epoch 4/5\n",
      "17153/17153 [==============================] - 38s 2ms/step - loss: 0.3476 - accuracy: 0.8369\n",
      "Epoch 5/5\n",
      "17153/17153 [==============================] - 27s 2ms/step - loss: 0.3468 - accuracy: 0.8371\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14b3e2b50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_input_values, train_input_classification, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2be8af87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2129/2129 - 4s - loss: 0.3464 - accuracy: 0.8371 - 4s/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3464040756225586, 0.8371140360832214]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_input_values,  test_input_classification, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f0545f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1651726 ]\n",
      " [0.00873801]\n",
      " [0.7357539 ]\n",
      " ...\n",
      " [0.47237718]\n",
      " [0.03232962]\n",
      " [0.34834814]]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = model.predict(test_input_values)\n",
    "print(test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a5d0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
